---
title: 'Пост обожания маркетинговых графиков Nvidia: RTX Edition.'
author: Юрий Крупенин
type: post
date: 2018-09-19T15:26:50+00:00
url: /2018/09/19/пост-обожания-маркетинговых-графико/
featured_image: 'https://i0.wp.com/usilenie.plus/wp-content/uploads/2018/09/nvidia_gamescom_2018_geforce_rtx_20_series_launch_7-e1553432822968.png?resize=450%2C450&ssl=1'
timeline_notification:
  - 1537370814
categories:
  - Технологии
  - Шитпостинг

---
Я обожаю графики Nvidia. Вы знаете, какие. Те, что достигли настолько культового уровня буллшиттинга, что мне сейчас было сложно найти что-то из настоящих, а не мемасиков по мотивам (а иногда &#8212; и сложно понять, к какой из двух категорий относится картинка).
  
&nbsp;
  
<figure style="width: 1200px" class="wp-caption aligncenter"><img class=" aligncenter" src="https://i1.wp.com/cdn.videocardz.com/1/2016/07/NVIDIA-GeForce-GTX-1060-vs-Radeon-RX-480-performance-1.jpg?resize=723%2C375" alt="[âIMG]" width="723" height="375" data-recalc-dims="1" /><figcaption class="wp-caption-text">Обратите внимание на шкалу.</figcaption></figure>
  
<figure style="width: 521px" class="wp-caption aligncenter"><img class=" aligncenter" src="https://i1.wp.com/www.dvhardware.net/news/nvidia_rv670_slide.jpg?resize=521%2C319&#038;ssl=1" alt="Image result for nvidia graphs" width="521" height="319" data-recalc-dims="1" /><figcaption class="wp-caption-text">Nvidia, миленькая, пожалуйта. ПОЖАЛУЙСТА.</figcaption></figure>
  
<figure style="width: 730px" class="wp-caption alignnone"><img src="https://i0.wp.com/news-cdn.softpedia.com/images/news2/GeForce-GTX-680-Is-40-faster-than-AMD-Radeon-HD-7970-2.jpg?resize=723%2C723&#038;ssl=1" width="723" height="723" data-recalc-dims="1" /><figcaption class="wp-caption-text">Серьёзно, я понятия не имею, настоящий ли этот.</figcaption></figure>
  
Тем не менее, я заявляю, что с приходом поколения RTX Nvidia закончила с враньём и перешла к искусству.
  
Прежде чем мы продолжим, я должен сказать следующие вещи:

  1. Новое поколение видеокарт Nvidia &#8212; это самый большой пересмотр пайплайна хардверно ускоренной графики в реальном времени со времён GeForce 3, если не ВООБЩЕ.
  2. Вы не имеете права относиться к рейтрейсингу в реальном времени (да, блядь, даже в составе гибридного пайплайна, и даже если он не работает на 60 кадрах в секунду в 4К-разрешении на карте ценой в вашу зарплату за полгода) как-то кроме как к абсолютному чуду.

&nbsp;
  
Но перейдём к уже знаменитой цифре в ДЕСЯТЬ ГИГАЛУЧЕЙ В СЕКУНДУ. Вот откуда она взялась:
  
&nbsp;
  
<img src="https://i2.wp.com/pbs.twimg.com/media/DnSZc7bXoAATSPl.jpg?w=723&#038;ssl=1" data-recalc-dims="1" />
  
На первый взгляд &#8212; не так плохо, правда? Я серьёзно ожидал, что этот результат получен на сцене, состоящей из единственного треугольника. Nvidia же взяла не самые сложные, но всё же относительно высокополигональные трёхмерные модели (и начала сравнивать производительность хардверно ускоренного решения с софтовым фоллбэком с предыдущего поколения, но опустим этот момент).
  
Ладно, если подумать ещё немного, то можно прикинуть, чем характеризуется первый интерсект для полностью помещающейся в кадр сцены, не имеющей сложных просматривающихся внутренних пространств. Относительно низкой глубиной лукапа BVH, конечно. Простим и это: было бы интересно посмотреть на цифры по датасету типа Sponza, да ещё с разных ракурсов, но то, что есть &#8212; уже непло&#8230;
  
&nbsp;
  
<figure id="attachment_196" aria-describedby="caption-attachment-196" style="width: 612px" class="wp-caption alignnone"><img data-attachment-id="196" data-permalink="https://usilenie.plus/2018/09/19/%d0%bf%d0%be%d1%81%d1%82-%d0%be%d0%b1%d0%be%d0%b6%d0%b0%d0%bd%d0%b8%d1%8f-%d0%bc%d0%b0%d1%80%d0%ba%d0%b5%d1%82%d0%b8%d0%bd%d0%b3%d0%be%d0%b2%d1%8b%d1%85-%d0%b3%d1%80%d0%b0%d1%84%d0%b8%d0%ba%d0%be/photo_2018-09-19_18-09-25/" data-orig-file="https://i1.wp.com/usilenie.plus/wp-content/uploads/2018/09/photo_2018-09-19_18-09-25.jpg?fit=612%2C109&ssl=1" data-orig-size="612,109" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="photo_2018-09-19_18-09-25" data-image-description="" data-medium-file="https://i1.wp.com/usilenie.plus/wp-content/uploads/2018/09/photo_2018-09-19_18-09-25.jpg?fit=300%2C53&ssl=1" data-large-file="https://i1.wp.com/usilenie.plus/wp-content/uploads/2018/09/photo_2018-09-19_18-09-25.jpg?fit=612%2C109&ssl=1" class="alignnone size-full wp-image-196" src="https://i0.wp.com/51.15.244.21/wp-content/uploads/2018/09/photo_2018-09-19_18-09-25.jpg?resize=612%2C109" alt="photo_2018-09-19_18-09-25" width="612" height="109" srcset="https://i1.wp.com/usilenie.plus/wp-content/uploads/2018/09/photo_2018-09-19_18-09-25.jpg?w=612&ssl=1 612w, https://i1.wp.com/usilenie.plus/wp-content/uploads/2018/09/photo_2018-09-19_18-09-25.jpg?resize=300%2C53&ssl=1 300w" sizes="(max-width: 612px) 100vw, 612px" data-recalc-dims="1" /><figcaption id="caption-attachment-196" class="wp-caption-text">Вайтпейпер архитектуры Turing, дамы и господа.</figcaption></figure>
  
Z-буфер.
  
Разумеется, primary-рейкаст можно пропустить и использовать бесплатные результаты из z-буфера растеризующего пайплайна (плюс трансформация скринспейс -> ворлдспейс, это ладно). Было бы глупо так не сделать, правда?
  
Итого, есть два варианта интерпретации цифры в ДЕСЯТЬ ГИГАЛУЧЕЙ В СЕКУНДУ:

  1. Это абсолютно синтетический результат для primary-рейкаста, который НЕ БУДЕТ ИСПОЛЬЗОВАТЬСЯ НИКОГДА (ну, на гибридном пайплайне, по крайней мере).
  2. Это именно полученные из z-буфера результаты и Nvidia просто выдаёт производительность растеризатора за производительность рейтрейсинга.

&nbsp;
  
В любом случае, это уже абсолютное искусство, но будет куда веселее, если потом окажется, что в данном случае это именно второй вариант. Nvidia это умеет. Я верю в Nvidia.
  
&nbsp;